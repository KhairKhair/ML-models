{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "## Avoid printing out warnings\n",
    "with warnings.catch_warnings():\n",
    "     warnings.filterwarnings(\"ignore\")\n",
    "     X, y = load_boston(return_X_y=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression With Closed-Form\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set error:  4.609066917948425\n",
      "Train set error:  5.180845679340211\n",
      "Average error:  4.894956298644319\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Avoid printing out warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    X, y = load_boston(return_X_y=True)\n",
    "\n",
    "\n",
    "# X has 506 datapoint with 13 features each\n",
    "\n",
    "ones = np.ones((X.shape[0],1))\n",
    "X = np.concatenate((ones,X), axis=1)\n",
    "k = 10\n",
    "kf = KFold(n_splits=k)\n",
    "\n",
    "mse_train, mse_test = 0,0\n",
    "for train,test in kf.split(X):\n",
    "    x = X[train]\n",
    "    x_t = np.transpose(x)\n",
    "    y_train = y[train]\n",
    "    thetas = np.matmul(np.matmul((np.linalg.inv(np.matmul(x_t,x))),x_t),y_train)\n",
    "\n",
    "    mse_train += np.sqrt(np.average([(np.matmul(thetas,X[i])-y[i])**2 for i in train]))\n",
    "    mse_test += np.sqrt(np.average([(np.matmul(thetas,X[i])-y[i])**2 for i in test]))\n",
    "\n",
    "print(\"Test set error: \", mse_train/k)\n",
    "print(\"Train set error: \", mse_test/k)\n",
    "print(\"Average error: \", (mse_test+mse_train)/(2*k))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression With Linear - Finding and Applying Best Lambda (alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha is:  31.622776601683793\n",
      "average error with best alpha:  4.8855840644939885\n",
      "Test set error with best alpha:  5.0279365263728835\n",
      "Train set error with best alpha:  4.743231602615094\n"
     ]
    }
   ],
   "source": [
    "## Avoid printing out warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    X, y = load_boston(return_X_y=True)\n",
    "\n",
    "\n",
    "# X has 506 datapoint with 13 features each\n",
    "\n",
    "ones = np.ones((X.shape[0],1))\n",
    "X = np.concatenate((ones,X), axis=1)\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k)\n",
    "\n",
    "Lambdas = np.logspace(1, 7, num=13)\n",
    "I = np.identity(X.shape[1])\n",
    "I[0,0] = 0\n",
    "\n",
    "#stores [highest_score, best_alpha]\n",
    "best = [10000,0]\n",
    "for alpha in Lambdas:\n",
    "    mse_test = 0\n",
    "    for train,test in kf.split(X):\n",
    "        x = X[train]\n",
    "        x_t = np.transpose(x)\n",
    "        y_train = y[train]\n",
    "        thetas = np.matmul(np.matmul((np.linalg.inv(np.matmul(x_t,x)+(alpha*I))),x_t),y_train)\n",
    "\n",
    "        mse_test += np.sqrt(np.average([(np.matmul(thetas,X[i])-y[i])**2 for i in test]))/k\n",
    "    if mse_test < best[0]:\n",
    "        best[0] = mse_test\n",
    "        best[1] = alpha\n",
    "\n",
    "\n",
    "alpha = best[1]\n",
    "mse_train, mse_test = 0,0\n",
    "for train,test in kf.split(X):\n",
    "    x = X[train]\n",
    "    x_t = np.transpose(x)\n",
    "    y_train = y[train]\n",
    "    thetas = np.matmul(np.matmul((np.linalg.inv(np.matmul(x_t,x)+(alpha*I))),x_t),y_train)\n",
    "\n",
    "    mse_test += np.sqrt(np.average([(np.matmul(thetas,X[i])-y[i])**2 for i in test]))/k\n",
    "    mse_train += np.sqrt(np.average([(np.matmul(thetas,X[i])-y[i])**2 for i in train]))/k\n",
    "\n",
    "print(\"best alpha is: \", best[1])\n",
    "print(\"average error with best alpha: \", (mse_train+mse_test)/2)\n",
    "print(\"Test set error with best alpha: \",mse_test)\n",
    "print(\"Train set error with best alpha: \", mse_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression With Polynomial - Finding and Applying Best Lambda(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha is:  3162277.6601683795\n",
      "average error with best alpha:  4.286747352235054\n",
      "Test set error with best alpha:  4.676965803221149\n",
      "Train set error with best alpha:  3.8965289012489572\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Avoid printing out warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    X, y = load_boston(return_X_y=True)\n",
    "\n",
    "\n",
    "# X has 506 datapoint with 13 features each\n",
    "\n",
    "#ones = np.ones((X.shape[0],1))\n",
    "#X = np.concatenate((ones,X), axis=1)\n",
    "X = PolynomialFeatures(degree=2).fit_transform(X)\n",
    "\n",
    "k = 10\n",
    "kf = KFold(n_splits=k)\n",
    "\n",
    "Lambdas = np.logspace(1, 7, num=13)\n",
    "I = np.identity(X.shape[1])\n",
    "I[0,0] = 0\n",
    "\n",
    "#stores [highest_score, best_alpha]\n",
    "best = [10000,0]\n",
    "for alpha in Lambdas:\n",
    "    mse_test = 0\n",
    "    for train,test in kf.split(X):\n",
    "        x = X[train]\n",
    "        x_t = np.transpose(x)\n",
    "        y_train = y[train]\n",
    "        thetas = np.matmul(np.matmul((np.linalg.inv(np.matmul(x_t,x)+(alpha*I))),x_t),y_train)\n",
    "\n",
    "        mse_test += np.sqrt(np.average([(np.matmul(thetas,X[i])-y[i])**2 for i in test]))/k\n",
    "    if mse_test < best[0]:\n",
    "        best[0] = mse_test\n",
    "        best[1] = alpha\n",
    "    \n",
    "    \n",
    "alpha = best[1]\n",
    "mse_train, mse_test = 0,0\n",
    "for train,test in kf.split(X):\n",
    "    x = X[train]\n",
    "    x_t = np.transpose(x)\n",
    "    y_train = y[train]\n",
    "    thetas = np.matmul(np.matmul((np.linalg.inv(np.matmul(x_t,x)+(alpha*I))),x_t),y_train)\n",
    "\n",
    "    mse_test += np.sqrt(np.average([(np.matmul(thetas,X[i])-y[i])**2 for i in test]))/k\n",
    "    mse_train += np.sqrt(np.average([(np.matmul(thetas,X[i])-y[i])**2 for i in train]))/k\n",
    "\n",
    "print(\"best alpha is: \", best[1])\n",
    "print(\"average error with best alpha: \", (mse_train+mse_test)/2)\n",
    "print(\"Test set error with best alpha: \" , mse_test)\n",
    "print(\"Train set error with best alpha: \",mse_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n",
      "Test set error:  8.004835415084644\n",
      "Train set error:  8.76630711837296\n",
      "[ 0.01   0.017  0.115  0.484  0.441  0.471  0.865  0.018  0.745  0.233\n",
      " -0.034  0.657  0.023 -0.195]\n"
     ]
    }
   ],
   "source": [
    "# Avoid printing out warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    X, y = load_boston(return_X_y=True)\n",
    "\n",
    "\n",
    "# X has 506 datapoint with 13 features each\n",
    "ones = np.ones((X.shape[0],1))\n",
    "X = np.concatenate((ones,X), axis=1)\n",
    "\n",
    "thetas = np.random.random((X.shape[1],))\n",
    "lr = 0.000001\n",
    "k = 10\n",
    "kf = KFold(n_splits=k)\n",
    "epochs = 10000\n",
    "mse_train, mse_test = 0,0\n",
    "print(np.shape(X))\n",
    "for train,test in kf.split(X):\n",
    "    thetas = np.random.random((X.shape[1],))\n",
    "    x = X[train]\n",
    "    x_t = np.transpose(x)\n",
    "    y_train = y[train]\n",
    "    for i in range(epochs):\n",
    "        grad = 2/len(x) * np.matmul(np.transpose(x), np.matmul(x,thetas)-y_train)\n",
    "        thetas = thetas - (lr * grad)\n",
    "\n",
    "    mse_train += np.sqrt(np.average([(np.matmul(thetas,X[i])-y[i])**2 for i in train]))\n",
    "    mse_test += np.sqrt(np.average([(np.matmul(thetas,X[i])-y[i])**2 for i in test]))\n",
    "\n",
    "print(\"Test set error: \", mse_train/k)\n",
    "print(\"Train set error: \", mse_test/k)\n",
    "print(np.round(thetas,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradiant Descent with LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set error:  8.245167297157625\n",
      "Train set error:  9.203670681916112\n",
      "[ 0.938  0.203  0.138  0.266  0.463  0.325  0.845  0.033  0.066  0.429\n",
      " -0.043  0.751  0.034 -0.289]\n"
     ]
    }
   ],
   "source": [
    "# Avoid printing out warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    X, y = load_boston(return_X_y=True)\n",
    "\n",
    "    \n",
    "# X has 506 datapoint with 13 features each\n",
    "ones = np.ones((X.shape[0],1))\n",
    "X = np.concatenate((ones,X), axis=1)\n",
    "\n",
    "I = np.identity(X.shape[1])\n",
    "I[0,0] = 0\n",
    "X = np.matmul(X,I)\n",
    "\n",
    "thetas = np.random.random((X.shape[1],))\n",
    "lr = 0.000001\n",
    "k = 10\n",
    "kf = KFold(n_splits=k)\n",
    "epochs = 10000\n",
    "mse_train, mse_test = 0,0\n",
    "alpha = 1\n",
    "\n",
    "for train,test in kf.split(X):\n",
    "    thetas = np.random.random((X.shape[1],))\n",
    "    x = X[train]\n",
    "    x_t = np.transpose(x)\n",
    "    y_train = y[train]\n",
    "    for i in range(epochs):\n",
    "        grad = (2/len(x) * np.matmul(np.transpose(x), np.matmul(x,thetas)-y_train)) + (alpha * np.sign(thetas))\n",
    "        thetas = thetas - (lr * grad)\n",
    "\n",
    "    mse_train += np.sqrt(np.average([(np.matmul(thetas,X[i])-y[i])**2 for i in train]))\n",
    "    mse_test += np.sqrt(np.average([(np.matmul(thetas,X[i])-y[i])**2 for i in test]))\n",
    "print(\"Test set error: \", mse_train/k)\n",
    "print(\"Train set error: \", mse_test/k)\n",
    "print(np.round(thetas,3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent with Elastic Net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set error:  7.858785943156794\n",
      "Train set error:  8.721560022256124\n",
      "[ 0.042 -0.098  0.132  0.232  0.855  0.054  0.602  0.049  0.255  0.351\n",
      " -0.019  0.017  0.047 -0.192]\n"
     ]
    }
   ],
   "source": [
    "# Avoid printing out warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    X, y = load_boston(return_X_y=True)\n",
    "\n",
    "# X has 506 datapoint with 13 features each\n",
    "ones = np.ones((X.shape[0],1))\n",
    "X = np.concatenate((ones,X), axis=1)\n",
    "\n",
    "I = np.identity(X.shape[1],)\n",
    "I[0,0] = 0\n",
    "X = np.matmul(X,I)\n",
    "\n",
    "thetas = np.random.random((X.shape[1],))\n",
    "lr = 0.000001\n",
    "k = 10\n",
    "kf = KFold(n_splits=k)\n",
    "epochs = 10000\n",
    "mse_train, mse_test = 0,0\n",
    "alpha_lasso = 0.7\n",
    "alpha_ridge = 1-alpha_lasso\n",
    "\n",
    "for train,test in kf.split(X):\n",
    "    thetas = np.random.random((X.shape[1],))\n",
    "    x = X[train]\n",
    "    x_t = np.transpose(x)\n",
    "    y_train = y[train]\n",
    "    for i in range(epochs):\n",
    "        grad = (2/len(x) * np.matmul(np.transpose(x), np.matmul(x,thetas)-y_train)) + (alpha_lasso * np.sign(thetas)) + (alpha_ridge * 2 * thetas) \n",
    "        thetas = thetas - (lr * grad)\n",
    "\n",
    "    mse_train += np.sqrt(np.average([(np.matmul(thetas,X[i])-y[i])**2 for i in train]))\n",
    "    mse_test += np.sqrt(np.average([(np.matmul(thetas,X[i])-y[i])**2 for i in test]))\n",
    "print(\"Test set error: \", mse_train/k)\n",
    "print(\"Train set error: \", mse_test/k)\n",
    "print(np.round(thetas,3))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
