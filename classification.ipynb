{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Image classification is the process of taking an input (like a picture) and outputting a class (like “cat”) or a probability that the input is a particular class (“there’s a 90% probability that this input is a cat”). You can look at a picture and know that you’re looking at a terrible shot of your own face, but how can a computer learn to do that? With a convolutional neural network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Goals\n",
    "We would like you to establish a neural network involving advanced DNN modules (i.e. convolution layers, RELU, pooling and fully connection layers and etc.) to distinguish the specific category of an input image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## Packages\n",
    "Let's first import the necessary packages,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import warnings\n",
    "from collections import namedtuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.jit.annotations import Optional, Tuple\n",
    "from torch import Tensor\n",
    "import os\n",
    "import numpy as np\n",
    "import os.path\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torchvision.datasets as dset\n",
    "import torch.utils.data as data\n",
    "from ipywidgets import IntProgress\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## GPU Device Configuration\n",
    "Use the torch.device() and torch.cuda.is_available() functions to make sure you can use the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else: \n",
    "    device = 'cpu'\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Configuration\n",
    "### hyperparameters\n",
    "We then set up the hyper parameters.\n",
    "we need to define several hyper parameters for our model:\n",
    "1. learning rate\n",
    "2. batch size when training\n",
    "3. batch size when testing\n",
    "4. number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "trainBatchSize = 10\n",
    "testBatchSize = 10\n",
    "num_epochs = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory if it does not exist\n",
    "you can use os.path.exists() to check whether it exists and using os.makedirs to create a directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "###  Image processing\n",
    "Then, we define an image preprocessing object that our dataloader will use to preprocess our data. We use the pytorch API to preform the data processing.\n",
    "1. Use transforms.Compose()\n",
    "2. Use .RandomHorizontalFlip()\n",
    "3. You add any extra transforms you like.\n",
    "4. Create this transform for both the train set and test set. Note that for the test, we do not require any transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()])\n",
    "test_transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### We then download and prepare the data with the transforms defined above:\n",
    "1. Use command torchvision.datasets.CIFAR10() with root, train, download and transform positional arguments.\n",
    "2. Use the same command to create both train split and test split.\n",
    "3. Use torch.utils.data.DataLoader() to create the data loader based on the data we have.\n",
    "3. Use this command for both the training split data loader and test split data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_set = dset.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "train_loader = data.DataLoader(dataset=train_set, batch_size=trainBatchSize, shuffle=True)\n",
    "test_set = dset.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "test_loader = data.DataLoader(dataset=test_set, batch_size=testBatchSize, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### Inception Module with dimension reductions\n",
    "1. Create a python class called Inception which inherits nn.module\n",
    "\n",
    "2. Create a init function to init this python class\n",
    "    1. Require in_planes, kernel_1_x, kernel_3_in, kernel_3_x, kernel_5_in, kernel_5_x and pool_planes 7 arguments.\n",
    "    \n",
    "    2. There are 4 Sequential blocks: b1,b2,b3,b4\n",
    "    \n",
    "    3. b1 is a block that consists of 2D convolution, a 2D batch normalization layer and a ReLU activation function\n",
    "    \n",
    "    4. b2 is a block that consists of two 2D convolutions, two 2D batch normalization layers and two ReLU activation functions\n",
    "    \n",
    "    5. b3 is a block that consists of two 2D convolutions, two 2D batch normalization layers and two ReLU activation functions\n",
    "    \n",
    "    6. b4 is a block consists of a Maxpooling layer, a 2D convolution, a 2D batch normalization layer and a ReLU activation function\n",
    "    \n",
    "3. Create the forward function: the forward function will forward the input function though every block and return the concatenation of all the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_planes, kernel_1_x, kernel_3_in, kernel_3_x, kernel_5_in, kernel_5_x, pool_planes):\n",
    "        super(Inception, self).__init__()\n",
    "        # 1x1 conv branch\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, kernel_1_x, kernel_size=1),\n",
    "            nn.BatchNorm2d(kernel_1_x),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        # 1x1 conv -> 3x3 conv branch\n",
    "        self.b2 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, kernel_3_in, kernel_size=1),\n",
    "            nn.BatchNorm2d(kernel_3_in),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(kernel_3_in, kernel_3_x, kernel_size=3, padding=1), \n",
    "            nn.BatchNorm2d(kernel_3_x),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "\n",
    "        # 1x1 conv -> 5x5 conv branch\n",
    "        self.b3 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, kernel_5_in, kernel_size=1),\n",
    "            nn.BatchNorm2d(kernel_5_in),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(kernel_5_in, kernel_5_x, kernel_size=5, padding=2), \n",
    "            nn.BatchNorm2d(kernel_5_x),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "         \n",
    "\n",
    "         #3x3 max pool -> 1x1 conv branch\n",
    "        self.b4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size = 3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_planes, pool_planes, kernel_size=1),\n",
    "            nn.BatchNorm2d(pool_planes),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "       \n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.b1(x)\n",
    "        out2 = self.b2(x)\n",
    "        out3 = self.b3(x)\n",
    "        out4 = self.b4(x)\n",
    "        # Concatenate the outputs along the channel dimension\n",
    "        out = torch.cat([out1, out2, out3, out4], 1)\n",
    "        return out\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GoogleNet, self).__init__()  # Initialize the base class\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 192, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Inception(192, 64, 96, 128, 16, 32, 32),\n",
    "            Inception(256, 128, 128, 192, 32, 96, 64),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            Inception(480, 192, 96, 208, 16, 48, 64),\n",
    "            Inception(512, 160, 112, 224, 24, 64, 64),\n",
    "            Inception(512, 128, 128, 256, 24, 64, 64),\n",
    "            Inception(512, 112, 144, 288, 32, 64, 64),\n",
    "            Inception(528, 256, 160, 320, 32, 128, 128),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            Inception(832, 256, 160, 320, 32, 128, 128),\n",
    "            Inception(832, 384, 192, 384, 48, 128, 128),\n",
    "            nn.AvgPool2d(kernel_size=8, stride=1),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024, 10)  # Assuming the number of classes is 10\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we create the network and send it to the target device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GoogleNet().to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, we create:\n",
    " 1. An optimizer  (we use adam optimzer here)\n",
    " 2. A Criterion (CrossEntropy) function\n",
    " 3. A Scheduler which decays the learning rate of each parameter group by gamma once the number of epoch reaches one of the milestones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  # This includes Softmax\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=alpha)\n",
    "\n",
    "def train(epoch, print_=False):\n",
    "    model.train()  \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  \n",
    "        output = model(data)   \n",
    "        loss = criterion(output, target)  \n",
    "        loss.backward()  \n",
    "        optimizer.step() \n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()  \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():  \n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  \n",
    "            pred = output.argmax(dim=1, keepdim=True)  \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss}, Accuracy: {accuracy}\\n')\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "\n",
      "Test set: Average loss: 0.13788607055842877, Accuracy: 50.01\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  1\n",
      "\n",
      "Test set: Average loss: 0.10666430238336325, Accuracy: 62.65\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  2\n",
      "\n",
      "Test set: Average loss: 0.08210792545452714, Accuracy: 70.63\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  3\n",
      "\n",
      "Test set: Average loss: 0.07362969746962189, Accuracy: 74.33\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  4\n",
      "\n",
      "Test set: Average loss: 0.06317428857833148, Accuracy: 78.12\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  5\n",
      "\n",
      "Test set: Average loss: 0.061380000344477596, Accuracy: 78.68\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  6\n",
      "\n",
      "Test set: Average loss: 0.056543651121202854, Accuracy: 80.67\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  7\n",
      "\n",
      "Test set: Average loss: 0.05179872986916453, Accuracy: 82.3\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  8\n",
      "\n",
      "Test set: Average loss: 0.052038143932260576, Accuracy: 82.18\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  9\n",
      "\n",
      "Test set: Average loss: 0.05001246869293973, Accuracy: 82.89\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  10\n",
      "\n",
      "Test set: Average loss: 0.04766056085349992, Accuracy: 84.38\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  11\n",
      "\n",
      "Test set: Average loss: 0.04782959919469431, Accuracy: 84.38\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  12\n",
      "\n",
      "Test set: Average loss: 0.05275564864994958, Accuracy: 82.61\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  13\n",
      "\n",
      "Test set: Average loss: 0.04672233531130478, Accuracy: 83.97\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  14\n",
      "\n",
      "Test set: Average loss: 0.04455026142478455, Accuracy: 85.08\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  15\n",
      "\n",
      "Test set: Average loss: 0.04227408606612589, Accuracy: 86.35\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  16\n",
      "\n",
      "Test set: Average loss: 0.0487929273363814, Accuracy: 84.7\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  17\n",
      "\n",
      "Test set: Average loss: 0.0439178508219833, Accuracy: 86.13\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  18\n",
      "\n",
      "Test set: Average loss: 0.04121190777079901, Accuracy: 87.01\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  19\n",
      "\n",
      "Test set: Average loss: 0.046814758891383826, Accuracy: 85.96\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  20\n",
      "\n",
      "Test set: Average loss: 0.04113477549762465, Accuracy: 86.86\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  21\n",
      "\n",
      "Test set: Average loss: 0.045206918334038344, Accuracy: 85.9\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  22\n",
      "\n",
      "Test set: Average loss: 0.042717942230118204, Accuracy: 87.46\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  23\n",
      "\n",
      "Test set: Average loss: 0.043697278358440964, Accuracy: 86.99\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  24\n",
      "\n",
      "Test set: Average loss: 0.04218746022408013, Accuracy: 87.62\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  25\n",
      "\n",
      "Test set: Average loss: 0.04095291036139533, Accuracy: 87.61\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  26\n",
      "\n",
      "Test set: Average loss: 0.04244886196105217, Accuracy: 87.2\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  27\n",
      "\n",
      "Test set: Average loss: 0.04147472991882823, Accuracy: 87.46\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  28\n",
      "\n",
      "Test set: Average loss: 0.04253070313835633, Accuracy: 87.57\n",
      "\n",
      "-----------------------------------------------------\n",
      "Epoch:  29\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(\"Epoch: \", i)\n",
    "    train(num_epochs, True)\n",
    "    acc = test()\n",
    "    print(\"-----------------------------------------------------\")\n",
    "\n",
    "    if acc > 90:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
