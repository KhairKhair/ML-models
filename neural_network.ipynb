{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86a5aac7-3176-4d92-af2a-2f1c1f93b3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits #import the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "data = digits.data \n",
    "old_labels = digits.target  \n",
    "\n",
    "labels = np.zeros((data.shape[0], 10))\n",
    "labels[np.arange(data.shape[0]), old_labels] = 1\n",
    "\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=41)\n",
    "\n",
    "scale = StandardScaler()\n",
    "scale.fit_transform(train_data)\n",
    "scale.transform(test_data)\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    sig = sigmoid(x)\n",
    "    return sig * (1-sig)\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_prime(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return  1 - np.tanh(x)**2\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4375b60-7351-4e76-891b-a73aaf6af6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class net():\n",
    "    def __init__(self, act, act_prime, alpha) -> None:\n",
    "        self.act  = act\n",
    "        self.dact = act_prime\n",
    "        self.w_1 = np.random.randn(64,30) * np.sqrt(2/64)\n",
    "        self.w_2 = np.random.randn(30,10) * np.sqrt(2/30)\n",
    "\n",
    "        self.b_1, self.b_2 = np.zeros((1,30)), np.zeros((1,10))\n",
    "        self.alpha = alpha\n",
    "\n",
    "\n",
    "    def set_input(self, x):\n",
    "        self.A_0 = x\n",
    "\n",
    "    def forward_1(self):\n",
    "        self.Z_1 = (self.A_0 @ self.w_1) + self.b_1\n",
    "        self.A_1 = self.act(self.Z_1)\n",
    "        self.Z_2 = (self.A_1 @ self.w_2) + self.b_2\n",
    "        self.A_2 = self.act(self.Z_2)\n",
    "\n",
    "    def loss(self, label):\n",
    "        return (self.A_2 - label)**2\n",
    "\n",
    "    def loss_prime(self, label):\n",
    "        return 2*(self.A_2 - label)\n",
    "\n",
    "    def grad(self, label):\n",
    "        dE_dA2 = self.loss_prime(label)\n",
    "        dA2_dZ2 = self.dact(self.Z_2)\n",
    "        dZ2_dW2 = self.A_1.T\n",
    "        self.dE_dW2 = dZ2_dW2 @ (dE_dA2 * dA2_dZ2)\n",
    "        self.dE_dB2 = np.sum(dE_dA2 * dA2_dZ2, axis=0) \n",
    "\n",
    "        dZ2_A1 = self.w_2\n",
    "        dA1_Z1 = self.dact(self.Z_1)\n",
    "        dZ1_dW1 = self.A_0\n",
    "\n",
    "        self.dE_dW1 = dZ1_dW1.T @ (((dE_dA2 * dA2_dZ2) @ dZ2_A1.T) * dA1_Z1)\n",
    "        self.dE_dB1 = np.sum((((dE_dA2 * dA2_dZ2) @ dZ2_A1.T) * dA1_Z1), axis=0)\n",
    "\n",
    "    def update(self, label):\n",
    "        scalar = label.shape[0]\n",
    "        self.w_2 = self.w_2 - (self.alpha * self.dE_dW2/scalar)\n",
    "        self.w_1 = self.w_1 - (self.alpha * self.dE_dW1/scalar)\n",
    "\n",
    "        self.b_2 = self.b_2 - (self.alpha * self.dE_dB2/scalar)\n",
    "        self.b_1 = self.b_1 - (self.alpha * self.dE_dB1/scalar)\n",
    "        \n",
    "\n",
    "#    def train(self, x, y):\n",
    "##        indices = np.random.permutation(x.shape[0])\n",
    "##        x = x[indices]\n",
    "##        y = y[indices]\n",
    "##\n",
    "\n",
    "    def train(self, x, y):\n",
    "        self.set_input(x)\n",
    "        self.forward_1()\n",
    "        self.grad(y)\n",
    "        self.update(y)\n",
    "\n",
    "    def test(self, x, y):\n",
    "        self.set_input(x)\n",
    "        self.forward_1()\n",
    "        predicted_labels = np.argmax(self.A_2, axis=1)\n",
    "        true_labels = np.argmax(y, axis=1)\n",
    "        accuracy = accuracy_score(predicted_labels, true_labels)\n",
    "        return accuracy,np.sum(self.loss(y))\n",
    "\n",
    "\n",
    "\n",
    "network = net(tanh,tanh_prime,0.0001)\n",
    "#for epoch in range(100):\n",
    "#    for i in range(30):\n",
    "#        network.train(train_data, train_labels)\n",
    "#    network.test(test_data, test_labels)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caa99e0e-f313-467f-afa5-592ff9f941bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "    Accuracy: 11.11111111111111\n",
      "    Test loss:  339.3347044250885\n",
      "Epoch: 10\n",
      "    Accuracy: 47.5\n",
      "    Test loss:  278.7822843307516\n",
      "Epoch: 20\n",
      "    Accuracy: 70.83333333333334\n",
      "    Test loss:  227.11885301485887\n",
      "Epoch: 30\n",
      "    Accuracy: 81.66666666666667\n",
      "    Test loss:  182.75193861037113\n",
      "Epoch: 40\n",
      "    Accuracy: 89.16666666666667\n",
      "    Test loss:  145.1408939270961\n",
      "Epoch: 50\n",
      "    Accuracy: 92.5\n",
      "    Test loss:  118.00254536085657\n",
      "Epoch: 60\n",
      "    Accuracy: 93.33333333333333\n",
      "    Test loss:  99.19928607938768\n",
      "Epoch: 70\n",
      "    Accuracy: 94.16666666666667\n",
      "    Test loss:  85.70591232754226\n",
      "Epoch: 80\n",
      "    Accuracy: 94.16666666666667\n",
      "    Test loss:  75.6481006858996\n",
      "Epoch: 90\n",
      "    Accuracy: 94.44444444444444\n",
      "    Test loss:  67.93435533019945\n"
     ]
    }
   ],
   "source": [
    "network = net(sigmoid,sigmoid_prime,0.001)\n",
    "for epoch in range(100):\n",
    "    for i in range(1000):\n",
    "        network.train(train_data, train_labels)\n",
    "        \n",
    "    acc, loss = network.test(test_data, test_labels)\n",
    "    if (epoch % 10) == 0:\n",
    "        print(\"Epoch:\", epoch)\n",
    "        print(\"    Accuracy:\" , acc*100)\n",
    "        print(\"    Test loss: \", loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35a0685-d68f-448f-800a-dc852c1e5a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "    Accuracy: 10.555555555555555\n",
      "    Test loss:  464.5288966466875\n",
      "Epoch: 10\n",
      "    Accuracy: 10.555555555555555\n",
      "    Test loss:  362.5962603802849\n"
     ]
    }
   ],
   "source": [
    "network = net(relu,relu_prime,0.00001)\n",
    "for epoch in range(1000):\n",
    "    for i in range(1000):\n",
    "        network.train(train_data, train_labels)\n",
    "        \n",
    "    acc, loss = network.test(test_data, test_labels)\n",
    "    if (epoch % 10) == 0:\n",
    "        print(\"Epoch:\", epoch)\n",
    "        print(\"    Accuracy:\" , acc*100)\n",
    "        print(\"    Test loss: \", loss)\n",
    "    if acc > 85:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "beef50e0-f1d7-47bd-bd8f-73afce190d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "    Accuracy: 9.444444444444445\n",
      "    Test loss:  1386.7519494203993\n",
      "Epoch: 10\n",
      "    Accuracy: 42.5\n",
      "    Test loss:  337.4819823622838\n",
      "Epoch: 20\n",
      "    Accuracy: 49.44444444444444\n",
      "    Test loss:  272.3192676820024\n",
      "Epoch: 30\n",
      "    Accuracy: 55.00000000000001\n",
      "    Test loss:  247.6054819100758\n",
      "Epoch: 40\n",
      "    Accuracy: 59.166666666666664\n",
      "    Test loss:  231.02634755147244\n",
      "Epoch: 50\n",
      "    Accuracy: 58.611111111111114\n",
      "    Test loss:  220.09287351774185\n",
      "Epoch: 60\n",
      "    Accuracy: 60.27777777777777\n",
      "    Test loss:  209.7743922439231\n",
      "Epoch: 70\n",
      "    Accuracy: 60.83333333333333\n",
      "    Test loss:  201.56638445137474\n",
      "Epoch: 80\n",
      "    Accuracy: 63.33333333333333\n",
      "    Test loss:  190.44421713957027\n",
      "Epoch: 90\n",
      "    Accuracy: 66.11111111111111\n",
      "    Test loss:  179.76150859740494\n",
      "Epoch: 100\n",
      "    Accuracy: 66.66666666666666\n",
      "    Test loss:  172.31939417009391\n",
      "Epoch: 110\n",
      "    Accuracy: 68.33333333333333\n",
      "    Test loss:  164.76345148631032\n",
      "Epoch: 120\n",
      "    Accuracy: 73.05555555555556\n",
      "    Test loss:  152.69841366462555\n",
      "Epoch: 130\n",
      "    Accuracy: 75.0\n",
      "    Test loss:  139.17587146890662\n",
      "Epoch: 140\n",
      "    Accuracy: 75.83333333333333\n",
      "    Test loss:  131.72748838305074\n",
      "Epoch: 150\n",
      "    Accuracy: 77.22222222222223\n",
      "    Test loss:  125.8426324425842\n",
      "Epoch: 160\n",
      "    Accuracy: 77.77777777777779\n",
      "    Test loss:  121.64747988060158\n",
      "Epoch: 170\n",
      "    Accuracy: 79.16666666666666\n",
      "    Test loss:  118.08736148441135\n",
      "Epoch: 180\n",
      "    Accuracy: 79.16666666666666\n",
      "    Test loss:  114.79247181954284\n",
      "Epoch: 190\n",
      "    Accuracy: 79.72222222222223\n",
      "    Test loss:  111.71163254613731\n",
      "Epoch: 200\n",
      "    Accuracy: 80.27777777777779\n",
      "    Test loss:  108.25347444838248\n",
      "Epoch: 210\n",
      "    Accuracy: 80.55555555555556\n",
      "    Test loss:  105.66843644269417\n",
      "Epoch: 220\n",
      "    Accuracy: 81.38888888888889\n",
      "    Test loss:  104.02123773956612\n",
      "Epoch: 230\n",
      "    Accuracy: 82.5\n",
      "    Test loss:  100.27257040057302\n",
      "Epoch: 240\n",
      "    Accuracy: 82.77777777777777\n",
      "    Test loss:  96.83405662347207\n",
      "Epoch: 250\n",
      "    Accuracy: 82.77777777777777\n",
      "    Test loss:  94.38194344102587\n",
      "Epoch: 260\n",
      "    Accuracy: 83.61111111111111\n",
      "    Test loss:  92.5996336544714\n",
      "Epoch: 270\n",
      "    Accuracy: 84.72222222222221\n",
      "    Test loss:  90.78619334290354\n",
      "Epoch: 280\n",
      "    Accuracy: 85.0\n",
      "    Test loss:  89.05798324134553\n",
      "Epoch: 290\n",
      "    Accuracy: 85.55555555555556\n",
      "    Test loss:  87.33401396747966\n",
      "Epoch: 300\n",
      "    Accuracy: 86.38888888888889\n",
      "    Test loss:  85.98555561050489\n",
      "Epoch: 310\n",
      "    Accuracy: 87.5\n",
      "    Test loss:  84.71834627166515\n",
      "Epoch: 320\n",
      "    Accuracy: 87.5\n",
      "    Test loss:  82.90610162740398\n",
      "Epoch: 330\n",
      "    Accuracy: 88.05555555555556\n",
      "    Test loss:  81.51250794771455\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5000\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m         \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     acc, loss \u001b[38;5;241m=\u001b[39m network\u001b[38;5;241m.\u001b[39mtest(test_data, test_labels)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[2], line 59\u001b[0m, in \u001b[0;36mnet.train\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_input(x)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_1()\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(y)\n",
      "Cell \u001b[0;32mIn[2], line 35\u001b[0m, in \u001b[0;36mnet.grad\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdE_dB2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(dE_dA2 \u001b[38;5;241m*\u001b[39m dA2_dZ2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \n\u001b[1;32m     34\u001b[0m dZ2_A1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_2\n\u001b[0;32m---> 35\u001b[0m dA1_Z1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZ_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m dZ1_dW1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA_0\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdE_dW1 \u001b[38;5;241m=\u001b[39m dZ1_dW1\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m (((dE_dA2 \u001b[38;5;241m*\u001b[39m dA2_dZ2) \u001b[38;5;241m@\u001b[39m dZ2_A1\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;241m*\u001b[39m dA1_Z1)\n",
      "Cell \u001b[0;32mIn[1], line 45\u001b[0m, in \u001b[0;36mtanh_prime\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtanh_prime\u001b[39m(x):\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m  \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtanh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "network = net(tanh,tanh_prime,0.0001)\n",
    "for epoch in range(5000):\n",
    "    for i in range(1000):\n",
    "        network.train(train_data, train_labels)\n",
    "        \n",
    "    acc, loss = network.test(test_data, test_labels)\n",
    "    if (epoch % 10) == 0:\n",
    "        print(\"Epoch:\", epoch)\n",
    "        print(\"    Accuracy:\" , acc*100)\n",
    "        print(\"    Test loss: \", loss)\n",
    "    if acc > 85:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9103220-214e-4c7e-af8d-fa43cec5c4af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
